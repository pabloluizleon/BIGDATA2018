{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CMCC](http://cmcc.ufabc.edu.br/images/logo_site.jpg)\n",
    "# **Spark + Python = PySpark**\n",
    "\n",
    "#### Esse notebook introduz os conceitos básicos do Spark através de sua interface com a linguagem Python. Como aplicação inicial faremos o clássico examplo de contador de palavras . Com esse exemplo é possível entender a lógica de programação funcional para as diversas tarefas de exploração de dados distribuídos.\n",
    "\n",
    "#### Para isso utilizaremos o livro texto [Trabalhos completos de William Shakespeare](http://www.gutenberg.org/ebooks/100) obtidos do  [Projeto Gutenberg](http://www.gutenberg.org/wiki/Main_Page).  Veremos que esse mesmo algoritmo pode ser empregado em textos de qualquer tamanho.\n",
    "\n",
    "#### ** Esse notebook contém:  **\n",
    "#### *Parte 1:* Criando uma base RDD e RDDs de tuplas\n",
    "#### *Parte 2:* Manipulando RDDs de tuplas\n",
    "#### *Parte 3:* Encontrando palavras únicas e calculando médias\n",
    "#### *Parte 4:* Aplicar contagem de palavras em um arquivo\n",
    "#### *Parte 5:* Similaridade entre Objetos\n",
    "#### Para os exercícios é aconselhável consultar a documentação da [API do PySpark](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Criando e Manipulando RDDs **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nessa parte do notebook vamos criar uma base RDD a partir de uma lista com o comando `parallelize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1a) Criando uma base RDD **\n",
    "#### Podemos criar uma base RDD de diversos tipos e fonte do Python com o comando `sc.parallelize(fonte, particoes)`, sendo fonte uma variável contendo os dados (ex.: uma lista) e particoes o número de partições para trabalhar em paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "sc = SparkContext.getOrCreate()\n",
    "ListaPalavras = ['gato', 'elefante', 'rato', 'rato', 'gato']\n",
    "palavrasRDD = sc.parallelize(ListaPalavras, 4)\n",
    "print(type(palavrasRDD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1b) Plural **\n",
    "\n",
    "#### Vamos criar uma função que transforma uma palavra no plural adicionando uma letra 's' ao final da string. Em seguida vamos utilizar a função `map()` para aplicar a transformação em cada palavra do RDD.\n",
    "\n",
    "#### Em Python (e muitas outras linguagens) a concatenação de strings é custosa. Uma alternativa melhor é criar uma nova string utilizando [`str.format()`](https://docs.python.org/2/library/string.html#format-string-syntax).\n",
    "\n",
    "#### Nota: a string entre os conjuntos de três aspas representa a documentação da função. Essa documentação é exibida com o comando `help()`. Vamos utilizar a padronização de documentação sugerida para o Python, manteremos essa documentação em inglês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gatos\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "def Plural(palavra):\n",
    "    \"\"\"Adds an 's' to `palavra`.\n",
    "\n",
    "    Args:\n",
    "        palavra (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with 's' added to it.\n",
    "    \"\"\"\n",
    "    return palavra + 's'\n",
    "\n",
    "print Plural('gato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Plural in module __main__:\n",
      "\n",
      "Plural(palavra)\n",
      "    Adds an 's' to `palavra`.\n",
      "    \n",
      "    Args:\n",
      "        palavra (str): A string.\n",
      "    \n",
      "    Returns:\n",
      "        str: A string with 's' added to it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Plural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert Plural('rato')=='ratos', 'resultado incorreto!'\n",
    "print ('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1c) Aplicando a função ao RDD **\n",
    "#### Transforme cada palavra do nosso RDD em plural usando [map()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.map) \n",
    "\n",
    "#### Em seguida, utilizaremos o comando  [collect()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collect) que retorna a RDD como uma lista do Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gatos', 'elefantes', 'ratos', 'ratos', 'gatos']\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "pluralRDD = palavrasRDD.map(lambda x : Plural(x))\n",
    "print pluralRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert pluralRDD.collect()==['gatos','elefantes','ratos','ratos','gatos'], 'valores incorretos!'\n",
    "print ('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Nota: ** utilize o comando `collect()` apenas quando tiver certeza de que a lista caberá na memória. Para gravar os resultados de volta em arquivo texto ou base de dados utilizaremos outro comando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1d) Utilizando uma função `lambda` **\n",
    "#### Repita a criação de um RDD de plurais, porém utilizando uma função lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gatos', 'elefantes', 'ratos', 'ratos', 'gatos']\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "pluralLambdaRDD = palavrasRDD.map(lambda x: x + 's')\n",
    "print pluralLambdaRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert pluralLambdaRDD.collect()==['gatos','elefantes','ratos','ratos','gatos'], 'valores incorretos!'\n",
    "print ('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1e) Tamanho de cada palavra **\n",
    "#### Agora use `map()` e uma função `lambda` para retornar o número de caracteres em cada palavra. Utilize `collect()` para armazenar o resultado em forma de listas na variável destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "pluralTamanho = (pluralRDD\n",
    "                 .map(lambda x: len(x))\n",
    "                 .collect()\n",
    "                 )\n",
    "print pluralTamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert pluralTamanho==[5,9,5,5,5], 'valores incorretos'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1f) RDDs de pares e tuplas **\n",
    "\n",
    "#### Para contar a frequência de cada palavra de maneira distribuída, primeiro devemos atribuir um valor para cada palavra do RDD. Isso irá gerar um base de dados (chave, valor). Desse modo podemos agrupar a base através da chave, calculando a soma dos valores atribuídos. No nosso caso, vamos atribuir o valor `1` para cada palavra.\n",
    "\n",
    "#### Um RDD contendo a estrutura de tupla chave-valor `(k,v) ` é chamada de RDD de tuplas ou *pair RDD*.\n",
    "\n",
    "#### Vamos criar nosso RDD de pares usando a transformação  `map()` com uma função `lambda()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gato', 1), ('elefante', 1), ('rato', 1), ('rato', 1), ('gato', 1)]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "palavraPar = palavrasRDD.map(lambda x: (x,1))\n",
    "print palavraPar.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert palavraPar.collect() == [('gato',1),('elefante',1),('rato',1),('rato',1),('gato',1)], 'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 2: Manipulando RDD de tuplas **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos manipular nossa RDD para contar as palavras do texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2a) Função `groupByKey()`  **\n",
    "\n",
    "#### A função [groupByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupByKey) agrupa todos os valores de um RDD através da chave (primeiro elemento da tupla) agregando os valores em uma lista.\n",
    "\n",
    "#### Essa abordagem tem um ponto fraco pois:\n",
    "  + #### A operação requer que os dados distribuídos sejam movidos em massa para que permaneçam na partição correta.\n",
    "  + #### As listas podem se tornar muito grandes. Imagine contar todas as palavras do Wikipedia: termos comuns como \"a\", \"e\" formarão uma lista enorme de valores que pode não caber na memória do processo escravo.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rato: [1, 1]\n",
      "elefante: [1]\n",
      "gato: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "palavrasGrupo = palavraPar.groupByKey()\n",
    "for chave, valor in palavrasGrupo.collect():\n",
    "    print '{0}: {1}'.format(chave, list(valor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert sorted(palavrasGrupo.mapValues(lambda x: list(x)).collect()) == [('elefante', [1]), ('gato',[1, 1]), ('rato',[1, 1])], 'Valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2b) Calculando as contagens **\n",
    "#### Após o  `groupByKey()` nossa RDD contém elementos compostos da palavra, como chave, e um iterador contendo todos os valores correspondentes aquela chave.\n",
    "#### Utilizando a transformação `map()` e a função `sum()`, contrua um novo RDD que consiste de tuplas (chave, soma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "contagemGroup = palavrasGrupo.map(lambda x: (x[0], len(x[1])))\n",
    "print contagemGroup.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert sorted(contagemGroup.collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2c) `reduceByKey` **\n",
    "#### Um comando mais interessante para a contagem é o  [reduceByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey) que cria uma nova RDD de tuplas.\n",
    "\n",
    "#### Essa transformação aplica a transformação `reduce()` vista na aula anterior para os valores de cada chave. Dessa forma, a função de transformação pode ser aplicada em cada partição local para depois ser enviada para redistribuição de partições, reduzindo o total de dados sendo movidos e não mantendo listas grandes na memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "from operator import add\n",
    "contagem = palavraPar.reduceByKey(add)\n",
    "print contagem.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert sorted(contagem.collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (2d) Agrupando os comandos **\n",
    "\n",
    "#### A forma mais usual de realizar essa tarefa, partindo do nosso RDD palavrasRDD, é encadear os comandos map e reduceByKey em uma linha de comando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "contagemFinal = (palavrasRDD\n",
    "                .map(lambda x: (x,1))\n",
    "                .reduceByKey(add)\n",
    "                 )\n",
    "print contagemFinal.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert sorted(contagemFinal.collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 3: Encontrando as palavras únicas e calculando a média de contagem **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3a) Palavras Únicas **\n",
    "\n",
    "#### Calcule a quantidade de palavras únicas do RDD. Utilize o mesmo pipeline anterior porém substituindo `.collect()` por outro método do API da RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "palavrasUnicas = contagemFinal.map(lambda x :1).count()\n",
    "print palavrasUnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert palavrasUnicas==3, 'valor incorreto!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (3b) Calculando a Média de contagem de palavras **\n",
    "\n",
    "#### Encontre a média de frequência das palavras utilizando o RDD `contagem`.\n",
    "\n",
    "#### Note que a função do comando `reduce()` é aplicada em cada tupla do RDD. Para realizar a soma das contagens, primeiro é necessário mapear o RDD para um RDD contendo apenas os valores das frequências (sem as chaves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1.67\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "# add é equivalente a lambda x,y: x+y\n",
    "from operator import add\n",
    "total = (contagemFinal\n",
    "         .map(lambda x: x[1])\n",
    "         .reduce(lambda x,y: x+y)\n",
    "         )\n",
    "media = total / float(palavrasUnicas)\n",
    "print total\n",
    "print round(media, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert round(media, 2)==1.67, 'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 4: Aplicar nosso algoritmo em um arquivo **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4a) Função `contaPalavras` **\n",
    "\n",
    "#### Para podermos aplicar nosso algoritmo genéricamente em diversos RDDs, vamos primeiro criar uma função para aplicá-lo em qualquer fonte de dados. Essa função recebe de entrada um RDD contendo uma lista de chaves (palavras) e retorna um RDD de tuplas com as chaves e a contagem delas nessa RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rato', 2), ('elefante', 1), ('gato', 2)]\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "def contaPalavras(chavesRDD):\n",
    "    \"\"\"Creates a pair RDD with word counts from an RDD of words.\n",
    "\n",
    "    Args:\n",
    "        chavesRDD (RDD of str): An RDD consisting of words.\n",
    "\n",
    "    Returns:\n",
    "        RDD of (str, int): An RDD consisting of (word, count) tuples.\n",
    "    \"\"\"\n",
    "    return (chavesRDD\n",
    "            .map(lambda x: (x,1))\n",
    "            .reduceByKey(add)\n",
    "           )\n",
    "\n",
    "print contaPalavras(palavrasRDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert sorted(contaPalavras(palavrasRDD).collect())==[('elefante',1), ('gato',2), ('rato',2)], 'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4b) Normalizando o texto **\n",
    "\n",
    "#### Quando trabalhamos com dados reais, geralmente precisamos padronizar os atributos de tal forma que diferenças sutis por conta de erro de medição ou diferença de normatização, sejam desconsideradas. Para o próximo passo vamos padronizar o texto para:\n",
    "  + #### Padronizar a capitalização das palavras (tudo maiúsculo ou tudo minúsculo).\n",
    "  + #### Remover pontuação.\n",
    "  + #### Remover espaços no início e no final da palavra.\n",
    " \n",
    "#### Crie uma função `removerPontuacao` que converte todo o texto para minúscula, remove qualquer pontuação e espaços em branco no início ou final da palavra. Para isso, utilize a biblioteca [re](https://docs.python.org/2/library/re.html) para remover todo texto que não seja letra, número ou espaço, encadeando com as funções de string para remover espaços em branco e converter para minúscula (veja [Strings](https://docs.python.org/2/library/stdtypes.html?highlight=str.lower#string-methods))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ola quem esta ai\n",
      "sem espaco esublinhado\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "import re\n",
    "def removerPontuacao(texto):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        texto (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^A-Za-z0-9 ]', '', texto).strip().lower()\n",
    "print (removerPontuacao('Ola, quem esta ai??!'))\n",
    "print (removerPontuacao(' Sem espaco e_sublinhado!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert removerPontuacao(' O uso de virgulas, embora permitido, nao deve contar. ')=='o uso de virgulas embora permitido nao deve contar', 'string incorreta!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4c) Carregando arquivo texto  **\n",
    "\n",
    "#### Para a próxima parte vamos utilizar o livro [Trabalhos completos de William Shakespeare](http://www.gutenberg.org/ebooks/100) do [Projeto Gutenberg](http://www.gutenberg.org/wiki/Main_Page). \n",
    "\n",
    "#### Para converter um texto em uma RDD, utilizamos a função `textFile()` que recebe como entrada o nome do arquivo texto que queremos utilizar e o número de partições.\n",
    "\n",
    "#### O nome do arquivo texto pode se referir a um arquivo local ou uma URI de arquivo distribuído (ex.: hdfs://).\n",
    "\n",
    "#### Vamos também aplicar a função `removerPontuacao()` para normalizar o texto e verificar as 15 primeiras linhas com o comando `take()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "project gutenbergs the complete works of william shakespeare by william: 1\n",
      "shakespeare: 2\n",
      ": 3\n",
      "this ebook is for the use of anyone anywhere in the united states and: 4\n",
      "most other parts of the world at no cost and with almost no restrictions: 5\n",
      "whatsoever  you may copy it give it away or reuse it under the terms: 6\n",
      "of the project gutenberg license included with this ebook or online at: 7\n",
      "wwwgutenbergorg  if you are not located in the united states youll: 8\n",
      "have to check the laws of the country where you are located before using: 9\n",
      "this ebook: 10\n",
      ": 11\n",
      "see at the end of this file  content note added in 2017: 12\n",
      ": 13\n",
      ": 14\n"
     ]
    }
   ],
   "source": [
    "# Apenas execute a célula\n",
    "import os.path\n",
    "\n",
    "arquivo = os.path.join('Data', 'pg100.txt') \n",
    "\n",
    "# lê o arquivo com textFile e aplica a função removerPontuacao        \n",
    "shakesRDD = (sc\n",
    "             .textFile(arquivo, 8)\n",
    "             .map(removerPontuacao)\n",
    "             )\n",
    "\n",
    "# zipWithIndex gera tuplas (conteudo, indice) onde indice é a posição do conteudo na lista sequencial\n",
    "# Ex.: sc.parallelize(['gato','cachorro','boi']).zipWithIndex() ==> [('gato',0), ('cachorro',1), ('boi',2)]\n",
    "# sep.join() junta as strings de uma lista através do separador sep. Ex.: ','.join(['a','b','c']) ==> 'a,b,c'\n",
    "print ('\\n'.join(shakesRDD\n",
    "                .zipWithIndex()\n",
    "                .map(lambda linha: '{0}: {1}'.format(linha[0],linha[1]))\n",
    "                .take(15)\n",
    "               ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4d) Extraindo as palavras **\n",
    "#### Antes de poder usar nossa função  `contaPalavras()`, temos ainda que trabalhar em cima da nossa RDD:\n",
    "  + #### Precisamos gerar listas de palavras ao invés de listas de sentenças.\n",
    "  + #### Eliminar linhas vazias.\n",
    " \n",
    "#### As strings em Python tem o método [split()](https://docs.python.org/2/library/string.html#string.split) que faz a separação de uma string por separador. No nosso caso, queremos separar as strings por espaço. \n",
    "\n",
    "#### Utilize a função `map()` para gerar um novo RDD como uma lista de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [u'project', u'gutenbergs', u'the', u'complete', u'works', u'of', u'william', u'shakespeare', u'by', u'william'], [u'shakespeare'], [], [u'this', u'ebook', u'is', u'for', u'the', u'use', u'of', u'anyone', u'anywhere', u'in', u'the', u'united', u'states', u'and']]\n",
      "147929\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "shakesPalavrasRDD = shakesRDD.map(lambda x: x.split())\n",
    "total = shakesPalavrasRDD.count()\n",
    "print shakesPalavrasRDD.take(5)\n",
    "print total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conforme deve ter percebido, o uso da função `map()` gera uma lista para cada linha, criando um RDD contendo uma lista de listas.\n",
    "\n",
    "#### Para resolver esse problema, o Spark possui uma função análoga chamada `flatMap()` que aplica a transformação do `map()`, porém *achatando* o retorno em forma de lista para uma lista unidimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'project', u'gutenbergs', u'the', u'complete', u'works']\n",
      "959359\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "shakesPalavrasRDD = shakesRDD.flatMap(lambda x: x.split())\n",
    "total = shakesPalavrasRDD.count()\n",
    "print (shakesPalavrasRDD.take(5))\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert total==959359, \"valor incorreto de palavras!\"\n",
    "print (\"OK\")\n",
    "assert shakesPalavrasRDD.take(5)==['project', 'gutenbergs', 'the', 'complete', 'works'],'lista incorreta de palavras'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reparem que o `flatMap` já eliminou as entradas vazias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (4f) Contagem de palavras **\n",
    "#### Agora que nossa RDD contém uma lista de palavras, podemos aplicar nossa função `contaPalavras()`.\n",
    "\n",
    "#### Aplique a função em nossa RDD e utilize a função `takeOrdered` para imprimir as 15 palavras mais frequentes.\n",
    "\n",
    "#### `takeOrdered()` pode receber um segundo parâmetro que instrui o Spark em como ordenar os elementos. Ex.:\n",
    "\n",
    "#### `takeOrdered(15, key=lambda x: -x)`: ordem decrescente dos valores de x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 29996\n",
      "and: 28353\n",
      "i: 21860\n",
      "to: 20885\n",
      "of: 18811\n",
      "a: 15992\n",
      "you: 14439\n",
      "my: 13191\n",
      "in: 12027\n",
      "that: 11782\n",
      "is: 9711\n",
      "not: 9068\n",
      "with: 8521\n",
      "me: 8271\n",
      "for: 8184\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "top15 = contaPalavras(shakesPalavrasRDD).takeOrdered(15, key=lambda x: -x[1])\n",
    "print '\\n'.join(map(lambda (w, c): '{0}: {1}'.format(w, c), top15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert top15 == [('the', 29996), ('and', 28353), ('i', 21860), ('to', 20885), ('of', 18811), ('a', 15992), ('you', 14439), ('my', 13191), ('in', 12027), ('that', 11782), ('is', 9711), ('not', 9068), ('with', 8521), ('me', 8271), ('for', 8184)],'valores incorretos!'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Parte 5: Similaridade entre Objetos **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nessa parte do laboratório vamos aprender a calcular a distância entre atributos numéricos, categóricos e textuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5a) Vetores no espaço Euclidiano **\n",
    "\n",
    "#### Quando nossos objetos são representados no espaço Euclidiano, medimos a similaridade entre eles através da *p-Norma* definida por:\n",
    "\n",
    "#### $$d(x,y,p) = (\\sum_{i=1}^{n}{|x_i - y_i|^p})^{1/p}$$\n",
    "\n",
    "#### As normas mais utilizadas são $p=1,2,\\infty$ que se reduzem em distância absoluta, Euclidiana e máxima distância:\n",
    "\n",
    "#### $$d(x,y,1) = \\sum_{i=1}^{n}{|x_i - y_i|}$$\n",
    "\n",
    "#### $$d(x,y,2) = (\\sum_{i=1}^{n}{|x_i - y_i|^2})^{1/2}$$\n",
    "\n",
    "#### $$d(x,y,\\infty) = \\max(|x_1 - y_1|,|x_2 - y_2|, ..., |x_n - y_n|)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vamos criar uma função pNorm que recebe como parâmetro p e retorna uma função que calcula a pNorma\n",
    "def pNorm(p):\n",
    "    \"\"\"Generates a function to calculate the p-Norm between two points.\n",
    "\n",
    "    Args:\n",
    "        p (int): The integer p.\n",
    "\n",
    "    Returns:\n",
    "        Dist: A function that calculates the p-Norm.\n",
    "    \"\"\"\n",
    "\n",
    "    def Dist(x,y):\n",
    "        return np.power(np.power(np.abs(x-y),p).sum(),1/float(p))\n",
    "    return Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, array([0.37454012, 0.95071431, 0.73199394, 0.59865848, 0.15601864,\n",
      "       0.15599452, 0.05808361, 0.86617615, 0.60111501, 0.70807258,\n",
      "       0.02058449, 0.96990985, 0.83244264, 0.21233911, 0.18182497,\n",
      "       0.18340451, 0.30424224, 0.52475643, 0.43194502, 0.29122914,\n",
      "       0.61185289, 0.13949386, 0.29214465, 0.36636184, 0.45606998,\n",
      "       0.78517596, 0.19967378, 0.51423444, 0.59241457, 0.04645041,\n",
      "       0.60754485, 0.17052412, 0.06505159, 0.94888554, 0.96563203,\n",
      "       0.80839735, 0.30461377, 0.09767211, 0.68423303, 0.44015249,\n",
      "       0.12203823, 0.49517691, 0.03438852, 0.9093204 , 0.25877998,\n",
      "       0.66252228, 0.31171108, 0.52006802, 0.54671028, 0.18485446,\n",
      "       0.96958463, 0.77513282, 0.93949894, 0.89482735, 0.59789998,\n",
      "       0.92187424, 0.0884925 , 0.19598286, 0.04522729, 0.32533033,\n",
      "       0.38867729, 0.27134903, 0.82873751, 0.35675333, 0.28093451,\n",
      "       0.54269608, 0.14092422, 0.80219698, 0.07455064, 0.98688694,\n",
      "       0.77224477, 0.19871568, 0.00552212, 0.81546143, 0.70685734,\n",
      "       0.72900717, 0.77127035, 0.07404465, 0.35846573, 0.11586906,\n",
      "       0.86310343, 0.62329813, 0.33089802, 0.06355835, 0.31098232,\n",
      "       0.32518332, 0.72960618, 0.63755747, 0.88721274, 0.47221493,\n",
      "       0.11959425, 0.71324479, 0.76078505, 0.5612772 , 0.77096718,\n",
      "       0.4937956 , 0.52273283, 0.42754102, 0.02541913, 0.10789143])), (1, array([0.03142919, 0.63641041, 0.31435598, 0.50857069, 0.90756647,\n",
      "       0.24929223, 0.41038292, 0.75555114, 0.22879817, 0.07697991,\n",
      "       0.28975145, 0.16122129, 0.92969765, 0.80812038, 0.63340376,\n",
      "       0.87146059, 0.80367208, 0.18657006, 0.892559  , 0.53934224,\n",
      "       0.80744016, 0.8960913 , 0.31800347, 0.11005192, 0.22793516,\n",
      "       0.42710779, 0.81801477, 0.86073058, 0.00695213, 0.5107473 ,\n",
      "       0.417411  , 0.22210781, 0.11986537, 0.33761517, 0.9429097 ,\n",
      "       0.32320293, 0.51879062, 0.70301896, 0.3636296 , 0.97178208,\n",
      "       0.96244729, 0.2517823 , 0.49724851, 0.30087831, 0.28484049,\n",
      "       0.03688695, 0.60956433, 0.50267902, 0.05147875, 0.27864646,\n",
      "       0.90826589, 0.23956189, 0.14489487, 0.48945276, 0.98565045,\n",
      "       0.24205527, 0.67213555, 0.76161962, 0.23763754, 0.72821635,\n",
      "       0.36778313, 0.63230583, 0.63352971, 0.53577468, 0.09028977,\n",
      "       0.8353025 , 0.32078006, 0.18651851, 0.04077514, 0.59089294,\n",
      "       0.67756436, 0.01658783, 0.51209306, 0.22649578, 0.64517279,\n",
      "       0.17436643, 0.69093774, 0.38673535, 0.93672999, 0.13752094,\n",
      "       0.34106635, 0.11347352, 0.92469362, 0.87733935, 0.25794163,\n",
      "       0.65998405, 0.8172222 , 0.55520081, 0.52965058, 0.24185229,\n",
      "       0.09310277, 0.89721576, 0.90041806, 0.63310146, 0.33902979,\n",
      "       0.34920957, 0.72595568, 0.89711026, 0.88708642, 0.77987555])), (2, array([0.64203165, 0.08413996, 0.16162871, 0.89855419, 0.60642906,\n",
      "       0.00919705, 0.10147154, 0.66350177, 0.00506158, 0.16080805,\n",
      "       0.54873379, 0.6918952 , 0.65196126, 0.22426931, 0.71217922,\n",
      "       0.23724909, 0.3253997 , 0.74649141, 0.6496329 , 0.84922341,\n",
      "       0.65761289, 0.5683086 , 0.09367477, 0.3677158 , 0.26520237,\n",
      "       0.24398964, 0.97301055, 0.39309772, 0.89204656, 0.63113863,\n",
      "       0.7948113 , 0.50263709, 0.57690388, 0.49251769, 0.19524299,\n",
      "       0.72245212, 0.28077236, 0.02431597, 0.6454723 , 0.17711068,\n",
      "       0.94045858, 0.95392858, 0.91486439, 0.3701587 , 0.01545662,\n",
      "       0.92831856, 0.42818415, 0.96665482, 0.96361998, 0.85300946,\n",
      "       0.29444889, 0.38509773, 0.85113667, 0.31692201, 0.16949275,\n",
      "       0.55680126, 0.93615477, 0.6960298 , 0.57006117, 0.09717649,\n",
      "       0.61500723, 0.99005385, 0.14008402, 0.51832965, 0.87737307,\n",
      "       0.74076862, 0.69701574, 0.70248408, 0.35949115, 0.29359184,\n",
      "       0.80936116, 0.81011339, 0.86707232, 0.91324055, 0.5113424 ,\n",
      "       0.50151629, 0.79829518, 0.64996393, 0.70196688, 0.79579267,\n",
      "       0.89000534, 0.33799516, 0.37558295, 0.09398194, 0.57828014,\n",
      "       0.03594227, 0.46559802, 0.54264463, 0.28654125, 0.59083326,\n",
      "       0.03050025, 0.03734819, 0.82260056, 0.36019064, 0.12706051,\n",
      "       0.52224326, 0.76999355, 0.21582103, 0.62289048, 0.08534746])), (3, array([0.05168172, 0.53135463, 0.54063512, 0.6374299 , 0.72609133,\n",
      "       0.97585208, 0.51630035, 0.32295647, 0.79518619, 0.27083225,\n",
      "       0.43897142, 0.07845638, 0.02535074, 0.96264841, 0.83598012,\n",
      "       0.69597421, 0.40895294, 0.17329432, 0.15643704, 0.2502429 ,\n",
      "       0.54922666, 0.71459592, 0.66019738, 0.2799339 , 0.95486528,\n",
      "       0.73789692, 0.55435405, 0.61172075, 0.41960006, 0.24773099,\n",
      "       0.35597268, 0.75784611, 0.01439349, 0.11607264, 0.04600264,\n",
      "       0.0407288 , 0.85546058, 0.70365786, 0.47417383, 0.09783416,\n",
      "       0.49161588, 0.47347177, 0.17320187, 0.43385165, 0.39850473,\n",
      "       0.6158501 , 0.63509365, 0.04530401, 0.37461261, 0.62585992,\n",
      "       0.50313626, 0.85648984, 0.65869363, 0.16293443, 0.07056875,\n",
      "       0.64241928, 0.02651131, 0.58577558, 0.94023024, 0.57547418,\n",
      "       0.38816993, 0.64328822, 0.45825289, 0.54561679, 0.94146481,\n",
      "       0.38610264, 0.96119056, 0.90535064, 0.19579113, 0.0693613 ,\n",
      "       0.100778  , 0.01822183, 0.09444296, 0.68300677, 0.07118865,\n",
      "       0.31897563, 0.84487531, 0.02327194, 0.81446848, 0.28185477,\n",
      "       0.11816483, 0.69673717, 0.62894285, 0.87747201, 0.73507104,\n",
      "       0.80348093, 0.28203457, 0.17743954, 0.75061475, 0.80683474,\n",
      "       0.99050514, 0.41261768, 0.37201809, 0.77641296, 0.34080354,\n",
      "       0.93075733, 0.85841275, 0.42899403, 0.75087107, 0.75454287])), (4, array([0.10312387, 0.90255291, 0.50525237, 0.82645747, 0.3200496 ,\n",
      "       0.89552323, 0.38920168, 0.01083765, 0.90538198, 0.09128668,\n",
      "       0.31931364, 0.95006197, 0.95060715, 0.57343789, 0.63183721,\n",
      "       0.44844552, 0.29321077, 0.32866455, 0.67251846, 0.75237453,\n",
      "       0.79157904, 0.78961814, 0.0912061 , 0.4944203 , 0.05755876,\n",
      "       0.54952888, 0.4415305 , 0.88770418, 0.35091501, 0.11706702,\n",
      "       0.14299168, 0.76151063, 0.61821806, 0.10112268, 0.08410681,\n",
      "       0.70096913, 0.07276301, 0.82186006, 0.70624223, 0.08134878,\n",
      "       0.08483771, 0.98663958, 0.3742708 , 0.37064215, 0.81279957,\n",
      "       0.94724858, 0.98600106, 0.75337819, 0.37625959, 0.08350072,\n",
      "       0.77714692, 0.55840425, 0.42422201, 0.90635439, 0.11119748,\n",
      "       0.4926251 , 0.01135364, 0.46866064, 0.05630328, 0.11881792,\n",
      "       0.11752625, 0.6492103 , 0.74604488, 0.58336877, 0.96217255,\n",
      "       0.37487058, 0.28571209, 0.86859913, 0.22359584, 0.96322254,\n",
      "       0.01215447, 0.96987883, 0.04315991, 0.89114311, 0.52770111,\n",
      "       0.9929648 , 0.07379656, 0.55385428, 0.96930254, 0.52309784,\n",
      "       0.62939864, 0.69574869, 0.45454106, 0.62755808, 0.58431431,\n",
      "       0.90115801, 0.04544638, 0.28096319, 0.95041148, 0.89026378,\n",
      "       0.45565675, 0.6201326 , 0.27738118, 0.18812116, 0.4636984 ,\n",
      "       0.35335223, 0.58365611, 0.07773464, 0.97439481, 0.98621074])), (5, array([0.69816171, 0.53609637, 0.30952762, 0.81379502, 0.68473117,\n",
      "       0.16261694, 0.91092718, 0.82253724, 0.94979991, 0.72571951,\n",
      "       0.6134152 , 0.41824304, 0.93272848, 0.86606389, 0.04521867,\n",
      "       0.02636697, 0.37646337, 0.81055333, 0.98727613, 0.15041689,\n",
      "       0.59413072, 0.38089086, 0.9699144 , 0.84211892, 0.8383287 ,\n",
      "       0.46869316, 0.4148195 , 0.27340707, 0.0563755 , 0.86472238,\n",
      "       0.81290101, 0.99971767, 0.99663684, 0.55543171, 0.76898742,\n",
      "       0.94476573, 0.84964739, 0.2473481 , 0.45054414, 0.12915942,\n",
      "       0.95405103, 0.60617463, 0.22864281, 0.67170068, 0.61812824,\n",
      "       0.35816272, 0.11355759, 0.6715732 , 0.5203077 , 0.77231839,\n",
      "       0.5201635 , 0.8521815 , 0.55190684, 0.56093797, 0.8766536 ,\n",
      "       0.40348287, 0.13401523, 0.02878268, 0.75513726, 0.62030955,\n",
      "       0.70407977, 0.21296416, 0.13637148, 0.01454467, 0.35058756,\n",
      "       0.58991769, 0.39224405, 0.43747492, 0.90415869, 0.34825547,\n",
      "       0.51398949, 0.78365301, 0.39654278, 0.6220867 , 0.86236371,\n",
      "       0.94952062, 0.14707348, 0.92658763, 0.49211629, 0.25824439,\n",
      "       0.45913576, 0.98003258, 0.49261809, 0.32875161, 0.63340085,\n",
      "       0.24014562, 0.07586333, 0.12887972, 0.12804584, 0.15190269,\n",
      "       0.13882717, 0.64087474, 0.18188008, 0.34566728, 0.89678841,\n",
      "       0.47396164, 0.66755774, 0.17231987, 0.19228902, 0.04086862])), (6, array([0.16893506, 0.27859034, 0.17701048, 0.08870253, 0.12063587,\n",
      "       0.46077877, 0.20633372, 0.36426986, 0.50341727, 0.69039483,\n",
      "       0.03931214, 0.7994104 , 0.62790039, 0.08175903, 0.87357862,\n",
      "       0.9208724 , 0.06107796, 0.27687765, 0.80620128, 0.74825969,\n",
      "       0.18452102, 0.20934932, 0.3704721 , 0.48452299, 0.61825477,\n",
      "       0.36891364, 0.46253472, 0.74747094, 0.0366832 , 0.25243694,\n",
      "       0.71334959, 0.89520684, 0.51167744, 0.53211349, 0.10717201,\n",
      "       0.44741237, 0.53261727, 0.2424705 , 0.26924323, 0.37728416,\n",
      "       0.0200712 , 0.32207917, 0.21144801, 0.32749735, 0.11976213,\n",
      "       0.89052728, 0.59359245, 0.67910232, 0.78917124, 0.4984422 ,\n",
      "       0.08692029, 0.53710654, 0.58684112, 0.74543947, 0.43165955,\n",
      "       0.1275803 , 0.28377591, 0.3630823 , 0.64591724, 0.5707783 ,\n",
      "       0.35609673, 0.98651525, 0.60577482, 0.23722679, 0.10178247,\n",
      "       0.15285914, 0.24595773, 0.16068137, 0.18656702, 0.28509517,\n",
      "       0.1733736 , 0.89676542, 0.08023375, 0.52451139, 0.41039683,\n",
      "       0.98237862, 0.1120389 , 0.3978556 , 0.96947043, 0.86550713,\n",
      "       0.81707207, 0.25790283, 0.17088759, 0.66864322, 0.92937599,\n",
      "       0.55676289, 0.57161269, 0.27997909, 0.76949293, 0.18704375,\n",
      "       0.32367924, 0.42543644, 0.50761038, 0.24240973, 0.11483682,\n",
      "       0.61062004, 0.28863055, 0.58123822, 0.15436272, 0.4811401 ])), (7, array([0.53258943, 0.05182354, 0.33660428, 0.13441468, 0.06337497,\n",
      "       0.98996023, 0.32235384, 0.80987445, 0.25464065, 0.68150272,\n",
      "       0.76022786, 0.59563874, 0.47157619, 0.41184091, 0.34886827,\n",
      "       0.92952914, 0.83061941, 0.96502691, 0.12429722, 0.73086748,\n",
      "       0.93834046, 0.18123307, 0.06649627, 0.74112065, 0.57447311,\n",
      "       0.84182878, 0.13977238, 0.79526731, 0.20162732, 0.16365594,\n",
      "       0.1642658 , 0.81457472, 0.66519722, 0.52306542, 0.35883048,\n",
      "       0.87720054, 0.39244511, 0.81659944, 0.43913491, 0.37694443,\n",
      "       0.46267979, 0.30137787, 0.74760938, 0.50272039, 0.2322127 ,\n",
      "       0.89957457, 0.38389122, 0.54355286, 0.90647211, 0.624238  ,\n",
      "       0.11689804, 0.93983212, 0.62770805, 0.33490561, 0.13927207,\n",
      "       0.79402519, 0.62007276, 0.53346109, 0.89389258, 0.78859721,\n",
      "       0.15167488, 0.31172207, 0.24848914, 0.74394629, 0.03353243,\n",
      "       0.56988968, 0.76245869, 0.87676564, 0.34208175, 0.8212573 ,\n",
      "       0.11063174, 0.84645229, 0.12748866, 0.39728729, 0.79729537,\n",
      "       0.14991743, 0.2292514 , 0.72225257, 0.72003654, 0.64114763,\n",
      "       0.69394844, 0.54272444, 0.25179906, 0.34569599, 0.18159772,\n",
      "       0.90845056, 0.58339179, 0.40085142, 0.4620058 , 0.94728334,\n",
      "       0.1533514 , 0.58622983, 0.50588868, 0.61145424, 0.01811018,\n",
      "       0.87212391, 0.93211828, 0.56513318, 0.69665082, 0.92249938])), (8, array([0.70723863, 0.15253904, 0.57628836, 0.60671505, 0.42413067,\n",
      "       0.73644424, 0.93436701, 0.92556851, 0.45083937, 0.11323805,\n",
      "       0.9848412 , 0.83889809, 0.12466268, 0.92084188, 0.86989636,\n",
      "       0.51883806, 0.59127544, 0.3990027 , 0.05476164, 0.33519724,\n",
      "       0.80285345, 0.00463202, 0.33349917, 0.39816869, 0.5373956 ,\n",
      "       0.91985562, 0.34634599, 0.3469532 , 0.73750125, 0.45221794,\n",
      "       0.22460482, 0.45243952, 0.14085702, 0.17638699, 0.49836777,\n",
      "       0.41892545, 0.9148459 , 0.3623939 , 0.58058835, 0.63226429,\n",
      "       0.01309446, 0.66353737, 0.17803597, 0.96107032, 0.14866273,\n",
      "       0.41462412, 0.08534967, 0.99687425, 0.50219501, 0.59538502,\n",
      "       0.06707648, 0.74996047, 0.20990559, 0.89805429, 0.20513964,\n",
      "       0.19068772, 0.03654967, 0.47206695, 0.56484113, 0.06570864,\n",
      "       0.77552762, 0.45328883, 0.52439027, 0.44076275, 0.40076306,\n",
      "       0.55964033, 0.15524025, 0.18192813, 0.86178562, 0.94611546,\n",
      "       0.37330932, 0.27074467, 0.64399954, 0.40873417, 0.02538636,\n",
      "       0.1561526 , 0.71597223, 0.65892394, 0.02709599, 0.22197216,\n",
      "       0.2310748 , 0.67189274, 0.01971054, 0.10410858, 0.79991609,\n",
      "       0.17854466, 0.65274611, 0.23818278, 0.09944139, 0.24317219,\n",
      "       0.72226693, 0.85569647, 0.83021986, 0.39718353, 0.66808514,\n",
      "       0.2049843 , 0.29314773, 0.89633582, 0.01300192, 0.08550853])), (9, array([0.20788626, 0.0265322 , 0.18143544, 0.58304156, 0.42142455,\n",
      "       0.89267171, 0.81744356, 0.34181735, 0.25942343, 0.37969241,\n",
      "       0.59029494, 0.26806364, 0.62414891, 0.40941165, 0.55204718,\n",
      "       0.43612653, 0.29446576, 0.94845331, 0.76360579, 0.14011318,\n",
      "       0.86846798, 0.4874312 , 0.89455223, 0.79985526, 0.4252135 ,\n",
      "       0.02246931, 0.26867736, 0.54163421, 0.63347822, 0.25788769,\n",
      "       0.13935607, 0.83493024, 0.98440218, 0.52569018, 0.17167929,\n",
      "       0.27230733, 0.01839068, 0.91429881, 0.11775108, 0.57651648,\n",
      "       0.27405522, 0.554178  , 0.65142039, 0.8297418 , 0.20642127,\n",
      "       0.01099583, 0.13688563, 0.90001864, 0.87389008, 0.5974131 ,\n",
      "       0.60051686, 0.66503667, 0.17537128, 0.91441195, 0.41877052,\n",
      "       0.38313853, 0.51891771, 0.04696597, 0.16628337, 0.73803362,\n",
      "       0.08279867, 0.60315211, 0.24534911, 0.38929561, 0.28869374,\n",
      "       0.35567272, 0.71904591, 0.29712172, 0.56640464, 0.4760504 ,\n",
      "       0.66367117, 0.93682974, 0.7325721 , 0.21494038, 0.03118314,\n",
      "       0.26226404, 0.59507793, 0.05142581, 0.49636625, 0.59684285,\n",
      "       0.33424389, 0.7709122 , 0.10659825, 0.07513778, 0.72818876,\n",
      "       0.49549132, 0.6884024 , 0.43482734, 0.24640203, 0.81910232,\n",
      "       0.79941588, 0.69469647, 0.27214514, 0.59023067, 0.3609739 ,\n",
      "       0.09158207, 0.91731358, 0.13681863, 0.95023735, 0.44600577]))]\n"
     ]
    }
   ],
   "source": [
    "# Vamos criar uma RDD com valores numéricos\n",
    "np.random.seed(42)\n",
    "numPointsRDD = sc.parallelize(enumerate(np.random.random(size=(10,100))))\n",
    "#print(numPointsRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 4.709048183663605 3.75119168897537\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "# Procure dentre os comandos do PySpark, um que consiga fazer o produto cartesiano da base com ela mesma\n",
    "cartPointsRDD = numPointsRDD.cartesian(numPointsRDD)\n",
    "\n",
    "# Aplique um mapa para transformar nossa RDD em uma RDD de tuplas ((id1,id2), (vetor1,vetor2))\n",
    "# DICA: primeiro utilize o comando take(1) e imprima o resultado para verificar o formato atual da RDD\n",
    "cartPointsParesRDD = cartPointsRDD.map(lambda x: ((x[0][0], x[1][0]), (x[0][1], x[1][1])))\n",
    "#print  cartPointsRDD.take(1)[0][0][1]\n",
    "#print  cartPointsRDD.take(2\n",
    "#print cartPointsParesRDD.take(1)\n",
    "\n",
    "\n",
    "# Aplique um mapa para calcular a Distância Euclidiana entre os pares\n",
    "Euclid = pNorm(2)\n",
    "distRDD = cartPointsParesRDD.map(lambda x: pNorm(2)(x[1][0], x[1][1]))\n",
    "\n",
    "\n",
    "# Encontre a distância máxima, mínima e média, aplicando um mapa que transforma (chave,valor) --> valor\n",
    "# e utilizando os comandos internos do pyspark para o cálculo da min, max, mean\n",
    "statRDD = distRDD.map(lambda x: x)\n",
    "\n",
    "minv, maxv, meanv = statRDD.min(), statRDD.max(), statRDD.mean()\n",
    "print minv, maxv, meanv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "assert (minv.round(2), maxv.round(2), meanv.round(2))==(0.0, 4.71, 3.75), 'Valores incorretos'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5b) Valores Categóricos **\n",
    "\n",
    "#### Quando nossos objetos são representados por atributos categóricos, eles não possuem uma similaridade espacial. Para calcularmos a similaridade entre eles podemos primeiro transformar nosso vetor de atrbutos em um vetor binário indicando, para cada possível valor de cada atributo, se ele possui esse atributo ou não.\n",
    "\n",
    "#### Com o vetor binário podemos utilizar a distância de Hamming  definida por:\n",
    "\n",
    "#### $$ H(x,y) = \\sum_{i=1}^{n}{x_i != y_i} $$\n",
    "\n",
    "#### Também é possível definir a distância de Jaccard como:\n",
    "\n",
    "#### $$ J(x,y) = \\frac{\\sum_{i=1}^{n}{x_i == y_i} }{\\sum_{i=1}^{n}{\\max(x_i, y_i}) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma função para calcular a distância de Hamming\n",
    "def Hamming(x,y):\n",
    "    \"\"\"Calculates the Hamming distance between two binary vectors.\n",
    "\n",
    "    Args:\n",
    "        x, y (np.array): Array of binary integers x and y.\n",
    "\n",
    "    Returns:\n",
    "        H (int): The Hamming distance between x and y.\n",
    "    \"\"\"\n",
    "    return (x!=y).sum()\n",
    "\n",
    "# Vamos criar uma função para calcular a distância de Jaccard\n",
    "def Jaccard(x,y):\n",
    "    \"\"\"Calculates the Jaccard distance between two binary vectors.\n",
    "\n",
    "    Args:\n",
    "        x, y (np.array): Array of binary integers x and y.\n",
    "\n",
    "    Returns:\n",
    "        J (int): The Jaccard distance between x and y.\n",
    "    \"\"\"\n",
    "    return (x==y).sum()/float( np.maximum(x,y).sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma RDD com valores categóricos\n",
    "catPointsRDD = sc.parallelize(enumerate([['alto', 'caro', 'azul'],\n",
    "                             ['medio', 'caro', 'verde'],\n",
    "                             ['alto', 'barato', 'azul'],\n",
    "                             ['medio', 'caro', 'vermelho'],\n",
    "                             ['baixo', 'barato', 'verde'],\n",
    "                            ]))\n",
    "#print catPointsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ['alto', 'caro', 'azul']), (1, ['medio', 'caro', 'verde']), (2, ['alto', 'barato', 'azul']), (3, ['medio', 'caro', 'vermelho']), (4, ['baixo', 'barato', 'verde'])]\n",
      "{'alto': 0, 'medio': 7, 'baixo': 5, 'barato': 2, 'azul': 4, 'verde': 6, 'caro': 3, 'vermelho': 1} 8\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "# Crie um RDD de chaves únicas utilizando flatMap\n",
    "chavesRDD = (catPointsRDD\n",
    "             .flatMap(lambda x: x[1])\n",
    "             .distinct()\n",
    "             )\n",
    "print   catPointsRDD.collect()         \n",
    "chaves = dict((v,k) for k,v in enumerate(chavesRDD.collect()))\n",
    "nchaves = len(chaves)\n",
    "print chaves, nchaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "valores incorretos!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-1397bc13cb30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mchaves\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'alto'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'caro'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'baixo'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'verde'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'azul'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'medio'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'barato'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vermelho'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valores incorretos!'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"OK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnchaves\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'número de chaves incorreta'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: valores incorretos!"
     ]
    }
   ],
   "source": [
    "\n",
    "assert chaves=={'alto': 2, 'caro': 0, 'baixo': 4, 'verde': 1, 'azul': 2, 'medio': 3, 'barato': 4, 'vermelho': 3}, 'valores incorretos!'\n",
    "print (\"OK\")\n",
    "\n",
    "assert nchaves==8, 'número de chaves incorreta'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([1., 0., 0., 1., 1., 0., 0., 0.])),\n",
       " (1, array([0., 0., 0., 1., 0., 0., 1., 1.])),\n",
       " (2, array([1., 0., 1., 0., 1., 0., 0., 0.])),\n",
       " (3, array([0., 1., 0., 1., 0., 0., 0., 1.])),\n",
       " (4, array([0., 0., 1., 0., 0., 1., 1., 0.]))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def CreateNP(atributos,chaves):  \n",
    "    \"\"\"Binarize the categorical vector using a dictionary of keys.\n",
    "\n",
    "    Args:\n",
    "        atributos (list): List of attributes of a given object.\n",
    "        chaves (dict): dictionary with the relation attribute -> index\n",
    "\n",
    "    Returns:\n",
    "        array (np.array): Binary array of attributes.\n",
    "    \"\"\"\n",
    "    \n",
    "    array = np.zeros(len(chaves))\n",
    "    for atr in atributos:\n",
    "        array[ chaves[atr] ] = 1\n",
    "    return array\n",
    "\n",
    "# Converte o RDD para o formato binário, utilizando o dict chaves\n",
    "binRDD = catPointsRDD.map(lambda rec: (rec[0],CreateNP(rec[1], chaves)))\n",
    "binRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tMin\tMax\tMean\n",
      "Hamming:\t0.00\t6.00\t3.52\n",
      "Jaccard:\t0.33\t2.67\t1.14\n"
     ]
    }
   ],
   "source": [
    "# EXERCICIO\n",
    "# Procure dentre os comandos do PySpark, um que consiga fazer o produto cartesiano da base com ela mesma\n",
    "cartBinRDD = binRDD.cartesian(binRDD)\n",
    "#print cartBinRDD.collect()\n",
    "\n",
    "# Aplique um mapa para transformar nossa RDD em uma RDD de tuplas ((id1,id2), (vetor1,vetor2))\n",
    "# DICA: primeiro utilize o comando take(1) e imprima o resultado para verificar o formato atual da RDD\n",
    "cartBinParesRDD = cartBinRDD.map(lambda x: ((x[0][0], x[1][0]), (x[0][1], x[1][1])))\n",
    "\n",
    "\n",
    "# Aplique um mapa para calcular a Distância de Hamming e Jaccard entre os pares\n",
    "hamRDD = cartBinParesRDD.map(lambda x: Hamming(x[1][0], x[1][1]))\n",
    "jacRDD = cartBinParesRDD.map(lambda x: Jaccard(x[1][0], x[1][1]))\n",
    "\n",
    "# Encontre a distância máxima, mínima e média, aplicando um mapa que transforma (chave,valor) --> valor\n",
    "# e utilizando os comandos internos do pyspark para o cálculo da min, max, mean\n",
    "statJRDD = jacRDD.map(lambda x : x)\n",
    "statHRDD = hamRDD.map(lambda x : x)\n",
    "\n",
    "Hmin, Hmax, Hmean = statHRDD.min(), statHRDD.max(), statHRDD.mean()\n",
    "Jmin, Jmax, Jmean = statJRDD.min(), statJRDD.max(), statJRDD.mean()\n",
    "\n",
    "print \"\\t\\tMin\\tMax\\tMean\"\n",
    "print \"Hamming:\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format(Hmin, Hmax, Hmean )\n",
    "print \"Jaccard:\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format( Jmin, Jmax, Jmean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "valores incorretos",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-fd5e2514d39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mHmin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5.00\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valores incorretos'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"OK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mJmin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4.00\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valores incorretos'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"OK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: valores incorretos"
     ]
    }
   ],
   "source": [
    "assert (Hmin.round(2), Hmax.round(2), Hmean.round(2)) == (0.00,5.00,2.40), 'valores incorretos'\n",
    "print (\"OK\")\n",
    "assert (Jmin.round(2), Jmax.round(2), Jmean.round(2)) == (0.60,4.00,1.90), 'valores incorretos'\n",
    "print (\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
